{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# headings\n",
    "%pylab inline\n",
    "import scipy, scipy.stats\n",
    "pylab.rcParams['figure.figsize'] = (8.0, 4.0)\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Detection of Dependencies between variables \n",
    "\n",
    "* Systematic Dependency between two (or more) variables is a frequent indicator for a causal relationship or a joint dependency\n",
    "\n",
    "<img src=\"images/dependency.png\" width=\"50%\">\n",
    "* A='a flash', B='a thunder' is a causal relation\n",
    "* A='a wet road', B='open umbrellas' $\\Rightarrow$ no causal relation but dependent on a joint cause C=\"it rains\"\n",
    "\n",
    "This motivates our interest on 2 questions:\n",
    "* how probable is the existence of a systematic dependency given the data\n",
    "* if given, how strong is the dependency?\n",
    "\n",
    "We first consider the case of nominal variables, i.e. values are in a discrete set without structure.\n",
    "* Note: continuous variables can be transformed into discrete problems by binning.\n",
    "\n",
    "* $\\Rightarrow$ Contingency table stores all information about the dependency of two variables.\n",
    "\n",
    "Example: size and price of a product (e.g. laptop), sample of 170 devices\n",
    "\n",
    "\n",
    "<table>\n",
    "<tr> <th>A\\B</th><th>cheap</th><th>expensive</th><th>sum</th></tr>\n",
    "<tr><td>small</td><td>85</td><td>17</td><td>102</td></tr>\n",
    "<tr><td>big</td><td>15</td><td>53</td><td>68</td></tr>\n",
    "<tr><td>sum</td><td>100</td><td>70</td><td>170</td></tr>\n",
    "</table>\n",
    "\n",
    "**Notation:** \n",
    "\n",
    "* $ N_{ij} = \\#$ of cases with $A$ = i-th value and $B$ = j-th value.\n",
    "* $ N_{i*} = \\sum\\limits_j N_{ij}~~ $ row marginal, sums over columns. \n",
    "* $ N_{*j} = \\sum\\limits_i N_{ij}~~ $ column marginal, sums over rows.\n",
    "* $ N_{**} = \\sum\\limits_{ij}N_{ij} = N ~~$ total number of data points  \n",
    "\n",
    "** Null hypothesis**: the variables $A$ and $B$ are independent.\n",
    "\n",
    "Under the assumption of a valid null hypothesis, we expect $N_{ij}= \\tilde{N_{ij}}$ with  \n",
    "$$\\frac{\\tilde N_{ij}}{N}= \\frac{N_{i*}}{N}\\cdot \\frac{N_{*j}}{N}$$\n",
    "\n",
    "* Note that the condition $ P(E \\cap F) = P(E) \\cdot P(F)$ holds for statistical independence of events $E$ and $F$.\n",
    "* The probabilities are estimated by the relative frequencies \n",
    "\n",
    "* Consider the 'hit number' $N_{ij}$ as a random variable\n",
    "* The variance $\\sigma^2_{ij}$ can be estimated as:\n",
    "$$ \\sigma^2_{ij}=\\frac{\\tilde N_{ij}}{N}\\cdot \\left(1-\\frac{\\tilde N_{ij}}{N}\\right)\\cdot N \\approx \\tilde N_{ij}$$\n",
    "\n",
    "* Note that the random variable can - again - be regarded as a Bernoulli process with hit probability $p=N_{ij}/N$\n",
    "* the variance in this case is $\\sigma^2 = npq$ with $q=1-p$. With the assumption that $q \\approx 1$ follows the above statement.\n",
    "\n",
    "$$\\Rightarrow \\left(\\frac{(N_{ij}-\\tilde N_{ij})}{\\sqrt{\\tilde N_{ij}}}\\right)$$ \n",
    "are random variables with mean 0 and variance 1 (assuming that $H_0$ holds)\n",
    "\n",
    "$$ \\Rightarrow \\chi^2= \\sum\\limits_{ij}\\frac{(N_{ij}-\\tilde N_{ij})^2}{\\tilde N_{ij}}$$ \n",
    "is approximately $\\chi^2$-distributed\n",
    " * Note: because for large $N_{ij}$ the Bernoulli distribution converges against the normal distribution\n",
    "* with $\\nu = I \\cdot J - I - J + 1$ degrees of freedoms, where \n",
    "$ I=\\mbox{number of rows and} ~~ J=\\mbox{number of columns}$ of the contingency table.\n",
    "* Note that the number of summands is $I\\cdot J$, minus the number of boundary conditions for row- and column marginals $I$ and $J$. However, this subtracts one too many as the sum of the marginals is equal $\\sum N_{\\star j} = \\sum N_{i \\star} = N$.\n",
    "* With that, for a given critical value $\\chi^2_c$ the probability of error is:\n",
    "$$ P(\\chi^2>\\chi^2_c) = Q(\\chi_c^2, \\nu) =\\int_{\\chi^2}^\\infty p(\\chi^2)d(\\chi^2)$$\n",
    "* $\\to$ the same decision procedure as with the $\\chi^2$-test.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Question: If the null hypothesis can be rejected, how strong is the dependency? **\n",
    "* Reparameterization, so that the value is independent of $I$ and $J$.\n",
    " \n",
    "The strength is essentially given by the value of $\\chi^2$, conventional normalizations are:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.1 Cramer's $V$:\n",
    "\n",
    "$$V:=\\sqrt{\\frac{\\chi^2}{N\\cdot \\min(I-1,J-1)}}\\quad \\in [0,1]$$\n",
    "where \n",
    "* $V=1 ~~\\Leftarrow$ perfect Association (i.e. one variable determines the other)\n",
    "* $V=0 ~~\\Leftarrow$ no association at all\n",
    "\n",
    "If $I=J=2$, $V$ is called '$\\phi$-Statistic'.\n",
    "\n",
    "* symmetric: does not depend on row/column choice, nor permutation of rows/columns. \n",
    "* Denominator = info on table dimension $\\to$ corrects for the problem that measures of association for tables of different dimension are difficult to compare directly.\n",
    "* used if $I\\neq J$\n",
    "\n",
    "### 2.4.2 Contingency coefficient:\n",
    "$$ C=\\sqrt{\\frac{\\chi^2}{\\chi^2 + N}} \\in [0,1[ $$\n",
    "\n",
    "* The value $C=1$ will never be reached\n",
    "* Is only useful to compare the strengths of association of tables with equal $(I, J)$\n",
    "* Both with $V$ and $C$ there is no direct statistical interpretation of values in between \n",
    " * For instance: if you observe an association between iris color of the groupier and the roulette color amounting to $V=0.028$, you can not derive from that value whether the association is strong enough to earn money on behalf of that.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Recommended reading:\n",
    " * Cramers V: http://faculty.vassar.edu/lowry/newcs.html\n",
    " * Contingency coefficient: https://en.wikipedia.org/wiki/Contingency_table\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ws2017EOT20171108]"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
