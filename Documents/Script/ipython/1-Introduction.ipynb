{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Introduction to Data Mining</h1>\n",
    "<h2 align=\"center\">Lecture, winter term 2018/2019, 5 CP</h2> \n",
    "<h3 align=\"center\">Thomas Hermann</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. What is Data Mining \n",
    "\n",
    "*Definition*: \"Data mining is the computational process of exploring and uncovering patterns in large data sets a.k.a. Big Data. It’s a subfield of computer science which blends many techniques from statistics, data science, database theory and machine learning.\" (from: http://www.kdnuggets.com/2016/06/rayli-history-data-mining.html)\n",
    "\n",
    "<img src=\"http://www.kdnuggets.com/wp-content/uploads/history-data-mining.jpg\">\n",
    "(Illustration from <a href=\"http://kdnuggets.com\">kdnuggets.com</a>)\n",
    "\n",
    "\n",
    "## 1.1. Goals\n",
    "\n",
    "The goal of Datamining is the discovery of hidden structures and regularities in usually large data collections, and to make these insights applicable.\n",
    "\n",
    "Alternative terms are 'Siftware' und 'Knowledge discovery in Data Bases' (KDD), (coined by Gregory Piatetsky-Shapiro)\n",
    "\n",
    "It's a misnomer: \n",
    "* It is not resulting in data (data are not mined) but of knowledge extraction.\n",
    "* It plays with the metaphor of mining (iron mining, gold mining) where few nuggets are hidden in a huge amount of ore / dirt.\n",
    "\n",
    "In the focus are coherences of empirical nature, which can only badly or not at all be derived from theoretical considerations, such as for instance the decision behaviour of customers.\n",
    "\n",
    "### Some Aspects\n",
    "\n",
    "* uncover hidden regularities in data bases, make them perceivable and usable.\n",
    "* Techniques to support the interpretation of large data collections\n",
    "* Transform **data** into **information**\n",
    " * Derivation of rules \n",
    " * Diagnosis of dependencies\n",
    " * Recognition of trends \n",
    " * Prognosis\n",
    " * Automatic Construction of Models \n",
    "* Exploratory Data Analysis\n",
    " * Visualization\n",
    " * Sonification \n",
    " * HCI for improved navigation of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Related Procedures \n",
    "\n",
    "* **OLAP** (Online Analytical Processing): } \n",
    " * Organization of data collections into a multidimensional data cube\n",
    " * providing fast access modes for slices for interactive exploration of mostly simple coherences between dimensions\n",
    " * Typically as a client-server architecture.\n",
    "\n",
    "* ** Statistical Analysis** \n",
    " * are primarily *deductive*:  a (whereever coming from) hypothesis is tested at hand of available data (e.g. computing the significance)\n",
    " * The goal of Data Mining is in contrast to that primarily **inductive**: at hand of data we aim at new good hypothesis or models on coherences between attributes. \n",
    "* Statistical Methods serve as important tool to evaluate discovered patterns/rules/structures concerning their significance\n",
    "\n",
    "** Data Mining = EDA + CDA ** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Evolution of the field \n",
    "\n",
    "The field of data mining established since the begin of the 90ies\n",
    "* 1989: first KDD workshop at AAAi 89 (Piatetsky-Shapiro)\n",
    "* 1991, 1993: further workshops\n",
    "* 1995: first international conference at IJCAI 95\n",
    "* 1996: NRW Forschungsverbund \"Virtuelle Wissensfabrik\"\n",
    "* 1997: first journals: Datamining & Knowledge Discovery, and Intelligent Data Analysis\n",
    "* 1997++: Machine Learning\n",
    "* 2001: William S. Cleveland introduces the term _Data Science_ in his paper \"Data Science: An Action Plan for Expanding the Technical Areas of the Field of Statistics\"\n",
    "* 2008++: Big Data\n",
    " * \"Big data usually includes data sets with sizes beyond the ability of commonly used software tools to capture, curate, manage, and process data within a tolerable elapsed time\" (Snijders, C.; Matzat, U.; Reips, U.-D. (2012). \"'Big Data': Big gaps of knowledge in the field of Internet\". International Journal of Internet Science. 7: 1–5.)\n",
    " * famous 3 Vs: volume (amount of data), velocity (in/out speed of data), and variety (various data types and sources). \n",
    " * Due to massive growth of digital data over the computer age:\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/7/7c/Hilbert_InfoGrowth.png/400px-Hilbert_InfoGrowth.png\">\n",
    "* about 2010++: Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Neighboring Fields\n",
    "\n",
    "There are tight connections of data mining / KDD with many neighboring disciplines:\n",
    "\n",
    "* Pattern Recognition\n",
    "* Data Analysis, Statistics\n",
    "* Neural Networks / Deep Learning\n",
    "* Maschine Learning \n",
    "* Visualization, Computer Graphics\n",
    "* Databases, knowledge-based systems\n",
    "* Cognitive Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Basic Cases for Datamining\n",
    "\n",
    "* Whereever data are available in abundance and where the underlying laws are not sufficiently known (or applicable).\n",
    "\n",
    "The majority of applications lies in business, particularly the analysis of customer behavior:\n",
    "\n",
    " * **Segmentation of Customer types (\"Kundensegmentierung\")**: what types of customers can be discerned and what are their essential differences?\n",
    "\n",
    " * **Churn-Analysis**: what factors let customers go to other providers? How can the customers' loyality be increased?\n",
    "*(churn = Butter-Rührfass, aufrühren)*\n",
    "\n",
    " * **Fraud-Analysis**: what patterns (e.g. while using internet services or mobile phone services) allow provides to assume/conclude incorrect or even fraudulent behaviours of the users?\n",
    "\n",
    " * **Target group analysis**: what target groups for an action (advertisement, bargain offer, survey, call for donations) is for the envisioned purpose the most promising?\n",
    "\n",
    " * **Buying behaviour**: What factors influence the buying behaviour of my customers in a wished manner? What prognosis can I make?\n",
    "\n",
    " * **Product marketing**: what factors make my product more attractive than those of the competitors? \n",
    "\n",
    " * **Portfolio management**: intelligent selection of product or stocks in order to optimize a certain target function (e.g. interest, popularity etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6. A typical Data Mining Example \n",
    "\n",
    "** Marketing optimization in an american catalogue company, historical example, approx 1997 ** \n",
    "\n",
    "* Order of Magnitude\n",
    " * 400 Mio USD annual turnover\n",
    " * several catalogue types \n",
    " * ca. 100 Mio catalogue sendings per year \n",
    " * more than 200 branches \n",
    "\n",
    "* Business goals: more accurate and thus more economic Marketing (Pinpoint Marketing) by better utilization of customer information\n",
    "\n",
    " * What customers contribute mostly to the sales? \n",
    " * what helps to bind these customer groups better?\n",
    " * How do the customers' interests distribute on the different catalogues and special offers? \n",
    " * Comparison of marketing use between large catalogues and smaller specialized catalogues \n",
    " * Dependency of the buying pattern from the season\n",
    " * more accurate, target group specific criteria for catalogue mailing\n",
    " * overarching goal: return-of-investment (ROI) optimization\n",
    "\n",
    "** Data Basis: ** \n",
    "\n",
    "* Customer address data base (ca. 10 GBytes)\n",
    "* demographic customer data (ca. 10 GBytes)\n",
    "* documented transactions (ca. 500 GBytes)\n",
    "* results from sales campaigns (ca. 2 GBytes)\n",
    "\n",
    "** Involved Groups: **\n",
    "\n",
    "* IT\n",
    "* Database Department\n",
    "* Marketing\n",
    "* Sales\n",
    "* Upper Management\n",
    "\n",
    "** Project process **\n",
    "\n",
    "* Initialization by the Marketing Dept.\n",
    "* Definition of Success criteria: resulting savings, increase of customer loyalty, etc.\n",
    "* Setting up the technical requirements (computer configuration, database setup, required tools)\n",
    "* tools: SAS Datamining tools, DB2, Oracle RDBMS under SQL\n",
    "* Data Selection: Sales Transaction of the past 36 months, sorted by volume and product type\n",
    "* Creation of a project dedicated data base\n",
    "* Data preparation:\n",
    " * Filtering inconsistent data\n",
    " * Treating missing values\n",
    "* Setup of forecast models \n",
    "* Mainly applied Methods:\n",
    " * logistic regression = regression for discrete output variables, modelling the logit $\\log(p(1)/(1-p(1))$ as linear combination of the input variables. \n",
    " * Neural networks\n",
    " * Decision trees \n",
    "* Optimization of model parameters and comparison of models\n",
    "* subsampling in order to accelerate the throughput:\n",
    " * 1 million training points, 0.5 million examples for validation and test.\n",
    " \n",
    "** Results:**\n",
    "\n",
    "* Identification of a customer segment of 30% which is responsible for the majority of the sales \n",
    "* better tuning of offers for this customer segment \n",
    "* better timing of sales campaigns for a more steady turnover\n",
    "* reduction of costs for catalogue sendings and advertisement \n",
    "* **Data preparation (Selection, Cleaning, Recoding, Fusing, etc) made 70-80% of the overall effort** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7 More Examples:\n",
    "\n",
    "* Pharmacy / Chemistry: Searching for Similarities between chemical compounds\n",
    "* Paper production: \n",
    " * Process modelling: finding relevant sensor values for best quality\n",
    " * describing process behaviour in form of rules\n",
    "* **Environmental Research**: Change of vegetation, atmosphere (smog, ozone, climate), pollutant concentraion, seizmographic data\n",
    "* Telematics:\n",
    "** Predicting inner city traffic\n",
    "** e.g. Cologne: 120 induction loops and data about events (concerts, sports events, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.8. Important Questions\n",
    "\n",
    "* How can we discern regularities from random fluctuations?\n",
    " * $\\rightarrow$ **Statistics**\n",
    "\n",
    "* What features are important? How to cope with the problems of high-dimensional data?\n",
    " * $\\to$ Methods for **Dimensionality Reduction**\n",
    "\n",
    "* How can we merge data in a meaningful way according to their similarity?\n",
    " * $\\to$ **Clustering techniques**\n",
    " \n",
    "* How can we perceptualize data\n",
    " * $\\to$ **Visualization and Sonification techniques**\n",
    " \n",
    "* How can we classify data?\n",
    " * $\\to$ **Classification methods**\n",
    " \n",
    "* How to model dependencies \n",
    " * $\\to$ **Model extraction and machine learning**\n",
    " \n",
    "* How can we forecast into the future?\n",
    " * $\\to$ **time series analysis**\n",
    " \n",
    "* How can we identify complex structures\n",
    " * $\\to$ techniques for the induction of **decision trees**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.9. Focus of this Lecture\n",
    "* Understanding the underlying problems in high-dimensional data analysis\n",
    "* Learning how central methods are rooted in mathematics\n",
    "* Learning by doing: implement and investigate algorithms to become familiar\n",
    "* Mastering the basics rather then knowing all details\n",
    " * NOT much interest in 'howto use existing data mining packages'\n",
    "* Providing a solid basis for more advanced data science courses "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[winter term 2018/2019: end of T1 (2018-10-10)]"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
