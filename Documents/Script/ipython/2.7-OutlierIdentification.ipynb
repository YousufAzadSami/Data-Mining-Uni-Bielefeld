{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# settings\n",
    "%pylab inline\n",
    "import scipy, scipy.stats\n",
    "pylab.rcParams['figure.figsize'] = (8.0, 4.0)\n",
    "from IPython.html.widgets import interact, fixed\n",
    "# import ipywidgets\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7. Identification of Outliers\n",
    "\n",
    "Outlier = Deviations from a model (ideal situation), measurement error \n",
    "\n",
    "The presence of outliers in data can severely corrupt the results of analysis \n",
    "\n",
    "<img src=\"images/Outlier.png\" width=\"50%\">\n",
    "\n",
    "* _Left_: Linear regression suggests increasing trend \n",
    "* _Right_: Outlier causes linear regression to suggest a decreasing trend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7.1. Outlier Detection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: when do we have to regard a data point as outlier?\n",
    "* requires comparison with expectation, for instance at hand of other data points, a model, or prior knowledge\n",
    " * For example: in the list of body sizes of students in [m]\n",
    "    $$ (1.78, 1.82, 1.68, 2.02, 1.72, 1.60, 172, 1.79, 1.85, 1.59, 1.94,...)$$\n",
    " * if you find the value 172, it is likely that the actual value should have been 1.72 and only a decimal point was lost, i.e. the value was entered in another unit [cm]. \n",
    " * such a value can be easily spotted and corrected. \n",
    " * what helps is semantic knowledge / domain knowledge\n",
    "* Often (in lack of such knowledge): expectation of a normal distribution of the data (after elimination of outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### z-Test\n",
    "\n",
    "Let's assume we wish to detect outliers in the feature $x_i$ of a $d$-dimensional data vector.\n",
    "\n",
    "Estimate \n",
    "* the expected value $\\hat \\mu_i$ \n",
    "* and the standard deviation $\\hat\\sigma_i$ \n",
    "* of data in the environment of each data point $\\vec{x}$ \n",
    " * this may require the choice of a suitable neighborhood \n",
    "* and compute\n",
    "$$ z_i = \\frac{| y_i - \\hat \\mu_i |}{\\sigma_i } $$\n",
    "\n",
    "* Data points with $z_i>C$ will be classified as outliers. \n",
    "* $C$ is an arbitrary threshold (e.g. standard is $C=3$).\n",
    "* Instead of using an heuristically chosen value for $C$: \n",
    " * $\\to$ implicit derivation by assumung a small fraction $\\alpha \\ll 1$ of outliers, e.g. 1%.\n",
    "* $C$ results from isolation of the condition\n",
    "$$\t1- \\int \\limits_{-C}^C P(s) ds = 2 \\int \\limits_{C}^\\infty P(s) ds = \\alpha $$\n",
    "where $$P(s)=\\frac{1}{\\sqrt{2\\pi}} \\exp(-s^2/2)$$ \n",
    "is the normal density function with mean 0 and variance 1.\n",
    "* as an improvement, when testing data point $\\vec{x}^\\alpha_i$, mean and sigma can be computed without including the checked 'potential outlier'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[WS2018EOT1107]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Z-scores can be misleading with small sample size $N$, because the maximum Z-score has an upper limit of $\\frac{(N−1)}{\\sqrt{N}}$.\n",
    "* A remedy is to use the modified Z-score\n",
    "$$ M_i = 0.6745 \\frac{x_i−q_{0.5}}{m_{AD}}$$\n",
    "where $q_{0.5}$ is the median (i.e. the 50% quantile) and $m_{AD}=median(|x_i-q_{0.5}|)$ is the median absolute deviation. \n",
    " * source: B. Iglewicz and D. Hoaglin (1993), \"Volume 16: How to Detect and Handle Outliers\", The ASQC Basic References in Quality Control: Statistical Techniques, E. F. Mykytka, Editor.\n",
    "* The authors recommend $M_i > 3.5$ as outlier criterion.\n",
    "\n",
    "**Problem**: \n",
    "* many outliers falsify the estimation of $\\hat\\mu_i, \\hat\\sigma_i^2$\n",
    "\n",
    "$\\Rightarrow$ ** Possible Improvements:**\n",
    "\n",
    "* replace means by more robust medians, or\n",
    "* so-called **Roesner-Test**: as long as the $z$-test delivers at least an outlier:\n",
    " * remove only the most extreme outlier $i$, i.e. $$z_i=\\max\\limits_j z_j$$ from the data set\n",
    " * repeat recursively with the remaining data set.\n",
    "* In case of multivariate data:\n",
    " * project data on selected axis and apply the $z$-test on the 1d-projections.\n",
    " * The choice of suitable axis can for instance be done by using Principal Component Analysis (see Sec. 3.3)\n",
    " * Example: Feature $x$: Age, $y$: number of children.\n",
    "  * $x=3$ is certainly not an outlier\n",
    "  * $y=2$ is certainly not an outlier\n",
    "  * but: $(x,y) = (3,2)$ is totally implausible\n",
    "  * $\\to$ univariate tests would not be capable to discover the outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 2.7.2 Outlier Management \n",
    "\n",
    "* What do we do if we detect an outlier?\n",
    "\n",
    "$\\to $ a set of measures / actions (ranging from minimal invasive to drastic)\n",
    "\n",
    "1. Marking:\n",
    " * data points remain in the data set, only creation of an additional mask $M$ with \n",
    "$$ M_{\\alpha k} = \\left\\{  \n",
    "\t\\begin{array}{rcl}\n",
    "\t\t1 & \\text{if} & x_k^\\alpha ~~ \\text{valid}\\\\\n",
    "\t\t0 & \\text{if} & x_k^\\alpha ~~ \\text{invalid}\\\\\n",
    "\t\\end{array}\n",
    "\t\\right.$$\n",
    "2. Correction:\n",
    " * replace the value by a plausible value:\n",
    "  * $\\to$ mean value of that feature\n",
    "  * $\\to$ e.g. kernel regression (using correct features as independent variables)\n",
    "3. Removal of the component\n",
    "4. Removal of the whole data vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4475232137638106"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using 4.: how many valid rows remain if a fraction of a (e.g. 10% => 0.1) \n",
    "# outliers are randomly distributed throughout the d-dimensional dataset?\n",
    "a=0.01; d=80; (1-a)**d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "(TH: end of 2015-11-23)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
