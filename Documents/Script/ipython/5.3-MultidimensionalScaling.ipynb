{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## settings\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib qt5\n",
    "import scipy, scipy.stats\n",
    "plt.rcParams['figure.figsize'] = (8.0, 4.0)\n",
    "from ipywidgets import interact, fixed\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\usepackage{amssymb} \\newcommand{\\R}{\\mathbb{R}} \\newcommand{\\vx}{\\vec{x}} \\newcommand{\\vy}{\\vec{y}} \\newcommand{\\vw}{\\vec{w}} \\newcommand{\\Wc}{{\\bf W}_c}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Multidimensional Scaling\n",
    "\n",
    "#### Goal\n",
    "* Construction of a low-dimensional 'projection' $\\R^D \\mapsto \\R^d$ which is trying to maintain distances as good as possible ('abstandstreu')\n",
    "* Example:\n",
    "<img src=\"images/multidim.png\" width=\"50%\">\n",
    " * Assume that the edge length is 1: the diagonal then is $\\sqrt{3}$, but $\\sqrt{5}$ in the non-distance-preserving projection.\n",
    "\n",
    "#### Given:\n",
    "* $\\vx_1 \\dots \\vx_n \\in \\R^D$ given data points\n",
    " * $D=$ dimension of the data space\n",
    "* $\\vec{\\phi}(\\vx_1) \\dots \\vec{\\phi}(\\vx_n) \\in \\R^d$ wanted low-dimensional image \n",
    " * $d=$ dimension of the projection space\n",
    "\n",
    "#### Goal: \n",
    "* to maximally preserve distances, i.e. \n",
    "$$\n",
    "\t\\|\\vec{\\phi}(\\vx_i)-\\vec{\\phi}(\\vx_j)\\|_d \n",
    "\t\\stackrel{!}{=}\n",
    "\t\\|\\vx_i-\\vx_j\\|_D \\quad\\forall ~i,j\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.1. Sammon-Mapping \n",
    "\n",
    "* results from the minimization of a cost function $E$ for distance distortions \n",
    "* source: IEEE Trans.Comp. C-18, May 1969 401-409.\n",
    "* Let \n",
    "\\begin{eqnarray} \n",
    "\tD_{ij}=\\| \\vx_i-\\vx_j \\|_D \n",
    "\t\t&=& \\mbox{ distance in the high-dimensional space}\\\\\n",
    "\td_{ij}=\\|\\vec{\\phi}(\\vx_i)-\\vec{\\phi}(\\vx_j) \\|_d \n",
    "\t\t&=& \\mbox{distance in the low-dimensional space}\n",
    "\\end{eqnarray}\n",
    "\n",
    "Then the Sammon-Mapping bases on the following approach for a cost function $E$\n",
    "$$\tE[\\phi]= \\frac{1}{\\sum\\limits_{i<j}D_{ij}} \\cdot \\sum\\limits_{i<j} \\frac{(d_{ij}-D_{ij})^2}{D_{ij}} $$\n",
    "* the scaling factor serves only for scaling invariance\n",
    " * it is a constant for a constant data set \n",
    "* the denominator downweighs the error for large data point distances:\n",
    " * distance deviations shall here be less culpable\n",
    "* $E$ is undefined for points $i,j$ with $D_{ij}=0$: such points need to be eliminated beforehand\n",
    " * alternatively one could protect the denominator from divergence by adding a small $\\epsilon$\n",
    "* Minimization can for instance be done by gradient descent w.r.t. to $\\phi$-parameters\n",
    "* This is usually a very high-dimensional minimization problem, the result of which is facilitated by good initial values \n",
    "* Useful initial conditions are for instance the projection of $\\vx_i$ on the linear subspace spanned by the \n",
    "$d$ eigenvectors corresponding to the largest eigenvalues of the der covariance matrix $C$.\n",
    "* A more flexible choice for $\\{ \\Phi(\\vx_i)\\}_i =$ table of target positions $(x_1^p, y_1^p, \\dots, x_N^p, y_n^p)$ \n",
    " * (p indicates that this is the coordinate in projection space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.2. Sammon-Mapping with a target table of coordinates\n",
    "\n",
    "The target points $\\Phi(\\vx_k) = \\vec{v}_k = \\left({x_k \\atop y_k}\\right) $ are here simply provided via a look-up table.\n",
    "\n",
    "The cost function in turn can be rewritten as \n",
    "$$\n",
    "E[\\Phi] = \\frac{1}{\\sum_{ij} D_{ij}} \\frac{1}{2} \\sum_i \\sum_{j\\not= i}\n",
    "\\frac{(x_i-x_j)^2+(y_i-y_j)^2 + D_{ij}^2 - 2 D_{ij}\\sqrt{(x_i-x_j)^2 + (y_i-y_j)^2}}{D_{ij}}\n",
    "$$\n",
    "\n",
    "With this, the gradient (here for the example of the x-component, y in complete analogy) becomes:\n",
    "$$\n",
    "\\frac{\\partial E}{\\partial x_i} = \n",
    "\\frac{1}{\\sum_{ij} D_{ij}} \\frac{1}{2} \\sum_{j\\not= i} \\frac{1}{D_{ij}}\n",
    "(2(x_i-x_j) - 2D_{ij}\\frac{1}{2d_{ij}} 2 (x_i-x_j))\n",
    "$$\n",
    "* here the chain rule is used for derivation\n",
    "* the sum over $i$ disappears\n",
    "\n",
    "Further simplification results in \n",
    "$$\n",
    "\\frac{\\partial E}{\\partial x_i} = \n",
    "\\frac{1}{\\sum\\limits_{ij} D_{ij}} \\left[ \\sum\\limits_j \\left(\\frac{1}{D_{ij}} - \\frac{1}{d_{ij}}\\right) (x_i-x_j) \\right]\n",
    "= \\frac{1}{\\sum\\limits_{ij} D_{ij}} \\left[ \\sum\\limits_j a_{ij} (x_i-x_j) \\right]\n",
    "$$\n",
    "with $$a_{ij} = \\left( \\frac{1}{D_{ij}} - \\frac{1}{d_{ij}}\\right) = \\frac{d_{ij}-D_{ij}}{D_{ij}d_{ij}}.$$\n",
    "\n",
    "The coefficients are positive (resp. negative), if the projection distance is larger (resp. smaller) than the original distance of points $i$i and $j$.\n",
    "\n",
    "From this the update step becomes:\n",
    "\n",
    "$$\n",
    "\\Delta \\vec{v_k} = -\\eta \\nabla_{\\vec{v_k}} E = -\\frac{\\eta}{\\sum\\limits_{j,i} D_{ij}} \\sum_j a_{kj} (\\vec{v}_k-\\vec{v}_j)\n",
    "$$\n",
    "\n",
    "<img src=\"images/sammon-adapt.png\" width=\"50%\">\n",
    "\n",
    "* each point connection between $\\vec{v}_i$ und $\\vec{v}_j$ effects as a spring with a forcefree length of $D_{ij}$\n",
    "* the spring excerts a force proportional to the distance difference $D_{ij}-d_{ij}$ towards the equilibrium.\n",
    "* if only a single point $\\vec{v}_i$ is allowed to move, the sum of all spring forces causes the point to oscillate around an ideal point which minimizes the overall distortion.\n",
    "* friction is usually added so that the mass moves right into the potential trough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.2. Variant: Non-metric multidimensional Scaling\n",
    "\n",
    "** Idea: ** Instead of a mapping that is true for distances, we aim at best possible maintenance of distance rank order\n",
    "* i.e. we don't look at the absolute distance but its rank in a sorted list, similar to the difference between linear correlation and rank correlation\n",
    "* method is known as ordinal method of MDS\n",
    "$$\tD_{ij} < D_{kl} \\Leftrightarrow d_{ij} < d_{kl} \\quad \\forall ~ i, k, l\n",
    "$$\n",
    "* Note that equality is not necessarily required\n",
    "\n",
    "** Advantage**: higher robustness w.r.t. the choice of the distance metrics $D$.\n",
    "\n",
    "* Solving the above equation can be done by minimizing a suitable cost function\n",
    "$$\t\\text{stress}^2 = E(D,\\phi_1 \\dots \\phi_n; \\Theta) \n",
    "\t:= \\frac{\\sum\\limits_{ij}(\\Theta(D_{ij})-d_{ij})^2}{\\sum\\limits_{ij}d_{ij}^2}\n",
    "$$\n",
    "\n",
    "* Minimization is done w.r.t. the image points $\\phi_1 \\dots \\phi_N$ and the function $\\Theta(\\cdot)$, from which we demand that it is monotonous increasing.\n",
    "* The introduction of $\\Theta(\\cdot)$ results in the property that only the rank order of given distances $D_{ij}$ is relevant for the optimal solution.\n",
    "* it can be shown that the minimum is obtained for a step function  $\\Theta(\\cdot)$ with maximal ${n \\choose 2}$ steps, where $n$ is the number of data points.\n",
    " * so that $\\Theta(\\cdot)$ can be parameterized accordingly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See for instance: Ripley: Pattern Recognition and Neural Networks, "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
